{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport math\n\nclass SplineLinearLayer(torch.nn.Module):\n    def __init__(self, input_dim, output_dim, num_knots=5, spline_order=3, \n                 noise_scale=0.1, base_scale=1.0, spline_scale=1.0, \n                 activation=torch.nn.SiLU, grid_epsilon=0.02, grid_range=[-1, 1], \n                 standalone_spline_scaling=True):\n        super(SplineLinearLayer, self).__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.num_knots = num_knots\n        self.spline_order = spline_order\n        self.grid_epsilon = grid_epsilon\n        self.grid_range = grid_range\n        self.standalone_spline_scaling = standalone_spline_scaling\n\n        self.knots = self._calculate_knots(grid_range, num_knots, spline_order)\n        self.base_weights = torch.nn.Parameter(torch.Tensor(output_dim, input_dim))\n        self.spline_weights = torch.nn.Parameter(torch.Tensor(output_dim, input_dim, num_knots + spline_order))\n        if standalone_spline_scaling:\n            self.spline_scales = torch.nn.Parameter(torch.Tensor(output_dim, input_dim))\n\n        self.noise_scale = noise_scale\n        self.base_scale = base_scale\n        self.spline_scale = spline_scale\n        self.activation = activation()\n\n        self._initialize_parameters()\n\n    def _initialize_parameters(self):\n        \"\"\"\n        Initializes the parameters of the layer.\n        \"\"\"\n        torch.nn.init.xavier_uniform_(self.base_weights, gain=math.sqrt(2))\n        noise = torch.rand(self.num_knots + 1, self.input_dim, self.output_dim) - 0.5\n        self.spline_weights.data.copy_(self.spline_scale * self._initialize_spline_weights(noise))\n        if self.standalone_spline_scaling:\n            torch.nn.init.xavier_uniform_(self.spline_scales, gain=math.sqrt(2))\n\n    def _calculate_knots(self, grid_range, num_knots, spline_order):\n        \"\"\"\n        Calculates the knots for the spline.\n\n        Args:\n            grid_range (list): Range of the grid.\n            num_knots (int): Number of knots for the spline.\n            spline_order (int): Order of the spline.\n\n        Returns:\n            torch.Tensor: Calculated knots.\n        \"\"\"\n\n        h = (grid_range[1] - grid_range[0]) / num_knots\n        knots = torch.arange(-spline_order, num_knots + spline_order + 1) * h + grid_range[0]\n        return knots.expand(self.input_dim, -1).contiguous()\n\n    def _initialize_spline_weights(self, noise):\n        \"\"\"\n        Initializes spline weights.\n\n        Args:\n            noise (torch.Tensor): Noise tensor.\n\n        Returns:\n            torch.Tensor: Initialized spline weights.\n        \"\"\"\n        return self._fit_curve_to_coefficients(self.knots.T[self.spline_order : -self.spline_order], noise)\n\n    def _compute_b_splines(self, x):\n        \"\"\"\n        Computes the B-spline basis functions.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n\n        Returns:\n            torch.Tensor: Computed B-spline basis functions.\n        \"\"\"\n        x = x.unsqueeze(-1)\n        bases = ((x >= self.knots[:, :-1]) & (x < self.knots[:, 1:])).to(x.dtype)\n        for k in range(1, self.spline_order + 1):\n            bases = ((x - self.knots[:, : -(k + 1)]) / (self.knots[:, k:-1] - self.knots[:, : -(k + 1)]) * bases[:, :, :-1] + \n                     (self.knots[:, k + 1 :] - x) / (self.knots[:, k + 1 :] - self.knots[:, 1:(-k)]) * bases[:, :, 1:])\n        return bases.contiguous()\n\n    def _fit_curve_to_coefficients(self, x, y):\n        A = self._compute_b_splines(x).transpose(0, 1)\n        B = y.transpose(0, 1)\n        solution = torch.linalg.lstsq(A, B).solution\n        return solution.permute(2, 0, 1).contiguous()\n\n    @property\n    def _scaled_spline_weights(self):\n        return self.spline_weights * (self.spline_scales.unsqueeze(-1) if self.standalone_spline_scaling else 1.0)\n\n    def forward(self, x):\n        base_output = F.linear(self.activation(x), self.base_weights)\n        spline_output = F.linear(self._compute_b_splines(x).view(x.size(0), -1), \n                                 self._scaled_spline_weights.view(self.output_dim, -1))\n        return base_output + spline_output\n\n    @torch.no_grad()\n    def _update_knots(self, x, margin=0.01):\n        \"\"\"\n        Updates the knots based on the input data.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n            margin (float): Margin value.\n\n        Returns:\n            None\n        \"\"\"\n        batch = x.size(0)\n        splines = self._compute_b_splines(x).permute(1, 0, 2)\n        orig_coeff = self._scaled_spline_weights.permute(1, 2, 0)\n        unreduced_spline_output = torch.bmm(splines, orig_coeff).permute(1, 0, 2)\n\n        x_sorted = torch.sort(x, dim=0)[0]\n        adaptive_knots = x_sorted[torch.linspace(0, batch - 1, self.num_knots + 1, dtype=torch.int64, device=x.device)]\n\n        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.num_knots\n        uniform_knots = torch.arange(self.num_knots + 1, dtype=torch.float32, device=x.device).unsqueeze(1) * uniform_step + x_sorted[0] - margin\n\n        knots = self.grid_epsilon * uniform_knots + (1 - self.grid_epsilon) * adaptive_knots\n        knots = torch.cat([\n            knots[:1] - uniform_step * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n            knots,\n            knots[-1:] + uniform_step * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n        ], dim=0)\n\n        self.knots.copy_(knots.T)\n        self.spline_weights.data.copy_(self._fit_curve_to_coefficients(x, unreduced_spline_output))\n\n\nclass KAN(torch.nn.Module):\n    \"\"\"\n    Initializes the KAN.\n\n    Args:\n        hidden_layers (list): List of hidden layer dimensions.\n        num_knots (int): Number of knots for the spline.\n        spline_order (int): Order of the spline.\n        noise_scale (float): Scale of the noise.\n        base_scale (float): Scale of the base weights.\n        spline_scale (float): Scale of the spline weights.\n        activation (torch.nn.Module): Activation function to use.\n        grid_epsilon (float): Epsilon value for the grid.\n        grid_range (list): Range of the grid.\n    \"\"\"\n    def __init__(self, hidden_layers, num_knots=5, spline_order=3, \n                 noise_scale=0.1, base_scale=1.0, spline_scale=1.0, \n                 activation=torch.nn.SiLU, grid_epsilon=0.02, grid_range=[-1, 1]):\n        super(KAN, self).__init__()\n        self.layers = torch.nn.ModuleList()\n        for in_dim, out_dim in zip(hidden_layers, hidden_layers[1:]):\n            self.layers.append(SplineLinearLayer(in_dim, out_dim, num_knots, spline_order, \n                                                 noise_scale, base_scale, spline_scale, \n                                                 activation, grid_epsilon, grid_range))\n\n    def forward(self, x, update_knots=False):\n        \"\"\"\n        Forward pass of the KAN.\n\n        Args:\n            x (torch.Tensor): Input tensor.\n            update_knots (bool): Whether to update knots during forward pass.\n\n        Returns:\n            torch.Tensor: Output tensor.\n        \"\"\"\n        for layer in self.layers:\n            if update_knots:\n                layer._update_knots(x)\n            x = layer(x)\n        return x\n\n    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n        \"\"\"\n        Computes the regularization loss of the KAN.\n\n        Args:\n            regularize_activation (float): Regularization strength for activation.\n            regularize_entropy (float): Regularization strength for entropy.\n\n        Returns:\n            torch.Tensor: Regularization loss.\n        \"\"\"\n        return sum(layer._regularization_loss(regularize_activation, regularize_entropy) for layer in self.layers)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-05T20:35:20.783686Z","iopub.execute_input":"2024-05-05T20:35:20.784463Z","iopub.status.idle":"2024-05-05T20:35:20.820056Z","shell.execute_reply.started":"2024-05-05T20:35:20.784411Z","shell.execute_reply":"2024-05-05T20:35:20.818626Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\n# Load MNIST\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\ntrainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\nvalset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\ntrainloader = DataLoader(trainset, batch_size=64, shuffle=True)\nvalloader = DataLoader(valset, batch_size=64, shuffle=False)\n\n# Define model\nmodel = KAN([28 * 28, 64, 10])\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Define optimizer\noptimizer = optim.AdamW(model.parameters(), lr=1e-3)\n\n# Define loss\ncriterion = nn.CrossEntropyLoss()\n\n# Define ReduceLROnPlateau scheduler\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=3, verbose=True)\n\nfor epoch in range(10):\n    # Train\n    model.train()\n    total_loss = 0\n    total_accuracy = 0\n    with tqdm(trainloader) as pbar:\n        for images, labels in pbar:\n            images = images.view(-1, 28 * 28).to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            output = model(images)\n            loss = criterion(output, labels)\n            loss.backward()\n            optimizer.step()\n            accuracy = (output.argmax(dim=1) == labels).float().mean()\n            total_loss += loss.item()\n            total_accuracy += accuracy.item()\n            pbar.set_postfix(loss=loss.item(), accuracy=accuracy.item())\n    total_loss /= len(trainloader)\n    total_accuracy /= len(trainloader)\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    val_accuracy = 0\n    with torch.no_grad():\n        for images, labels in valloader:\n            images = images.view(-1, 28 * 28).to(device)\n            labels = labels.to(device)\n            output = model(images)\n            val_loss += criterion(output, labels).item()\n            val_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n    val_loss /= len(valloader)\n    val_accuracy /= len(valloader)\n\n    # Step the scheduler based on validation loss\n    scheduler.step(val_loss)\n\n    print(f\"Epoch {epoch + 1}, Train Loss: {total_loss}, Train Accuracy: {total_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-05T20:58:06.837101Z","iopub.execute_input":"2024-05-05T20:58:06.837487Z","iopub.status.idle":"2024-05-05T21:03:27.134351Z","shell.execute_reply.started":"2024-05-05T20:58:06.837452Z","shell.execute_reply":"2024-05-05T21:03:27.133085Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"100%|██████████| 938/938 [00:28<00:00, 32.74it/s, accuracy=0.969, loss=0.187]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Train Loss: 0.39985033546461224, Train Accuracy: 0.8797641257995735, Val Loss: 0.254256592203335, Val Accuracy: 0.9242635350318471\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 938/938 [00:28<00:00, 32.97it/s, accuracy=0.969, loss=0.0618]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Train Loss: 0.21326004391683062, Train Accuracy: 0.937450026652452, Val Loss: 0.1866328773907368, Val Accuracy: 0.9432722929936306\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 938/938 [00:28<00:00, 32.61it/s, accuracy=1, loss=0.0466]    \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Train Loss: 0.1537492910165713, Train Accuracy: 0.9541244669509595, Val Loss: 0.1872036379767926, Val Accuracy: 0.9430732484076433\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 938/938 [00:28<00:00, 33.34it/s, accuracy=0.938, loss=0.361] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Train Loss: 0.12218124231101195, Train Accuracy: 0.9638359541577826, Val Loss: 0.1298399512117705, Val Accuracy: 0.9590963375796179\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 938/938 [00:28<00:00, 33.18it/s, accuracy=0.906, loss=0.283] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Train Loss: 0.1010753822310377, Train Accuracy: 0.9693663379530917, Val Loss: 0.1297462544593794, Val Accuracy: 0.9600915605095541\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 938/938 [00:28<00:00, 32.97it/s, accuracy=1, loss=0.0078]    \n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Train Loss: 0.08415830911530345, Train Accuracy: 0.9740471748400853, Val Loss: 0.1182966953511261, Val Accuracy: 0.9639729299363057\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 938/938 [00:28<00:00, 32.45it/s, accuracy=1, loss=0.0133]    \n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Train Loss: 0.06898970465495516, Train Accuracy: 0.9791277985074627, Val Loss: 0.11010273604836926, Val Accuracy: 0.9659633757961783\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 938/938 [00:29<00:00, 31.67it/s, accuracy=0.969, loss=0.0766]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Train Loss: 0.05821317545737007, Train Accuracy: 0.9815598347547975, Val Loss: 0.11406798961729547, Val Accuracy: 0.9656648089171974\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 938/938 [00:28<00:00, 32.68it/s, accuracy=0.969, loss=0.115] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Train Loss: 0.0482356712479752, Train Accuracy: 0.9848414179104478, Val Loss: 0.10855315757302159, Val Accuracy: 0.9675557324840764\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 938/938 [00:28<00:00, 32.86it/s, accuracy=1, loss=0.04]      \n","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Train Loss: 0.04032294703637566, Train Accuracy: 0.9876898987206824, Val Loss: 0.11066264958843103, Val Accuracy: 0.9679538216560509\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
